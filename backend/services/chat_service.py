# ì„¤ëª…: ìŠ¤ë§ˆíŠ¸ Q&A ë„ë©”ì¸ ë¡œì§(ë²¡í„° ê²€ìƒ‰ â†’ ì¬ì •ë ¬ â†’ LLM ë‹µë³€ ìƒì„± â†’ [n] ì¸ë¼ì¸ ì¸ìš© â†’ ERD ì €ì¥ìš© citation í…ìŠ¤íŠ¸ êµ¬ì„±)
from __future__ import annotations
from typing import List, Tuple
import uuid, re

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from fastapi import HTTPException

from langchain_community.vectorstores import Chroma
from sentence_transformers import CrossEncoder

from models.chat_domain import ChatSessionTable, QATurnTable
from models.vector_domain import VectorIndexTable
from services.ai_service_global import _EMBEDDINGS, llm, question_prompt  # ì´ë¯¸ ìˆëŠ” ê³µìš© ëª¨ë“ˆ

# Colab ì˜ˆì œì™€ ë™ì¼í•œ ì¬ì •ë ¬ ëª¨ë¸(ë¹ ë¥´ê³  ê°€ë²¼ì›€)
_reranker = CrossEncoder("BAAI/bge-reranker-base")

async def _get_vector_index(session: AsyncSession, user_id: uuid.UUID, subject_id: int) -> VectorIndexTable:
    """user+subject ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ 1í–‰ì„ ê°€ì ¸ì˜¨ë‹¤(ì—†ìœ¼ë©´ 404)."""
    q = await session.execute(
        select(VectorIndexTable).where(
            VectorIndexTable.user_id == user_id,
            VectorIndexTable.subject_id == subject_id
        )
    )
    row = q.scalar_one_or_none()
    if not row:
        # ì—…ë¡œë“œ/ì¸ë±ì‹±ì´ ì•„ì§ ì•ˆ ëœ ê³¼ëª©
        raise HTTPException(404, "No vector index for this subject. Upload materials first.")
    return row

def _load_chroma(index_row: VectorIndexTable) -> Chroma:
    """
    RDBì— ì €ì¥ëœ ì»¬ë ‰ì…˜ ì‹ë³„ì(ì´ë¦„/ê²½ë¡œ)ë¡œ Chromaë¥¼ ë¡œë“œí•œë‹¤.
    ì‹¤ì œ ì„ë² ë”©/ê²€ìƒ‰ì€ ë””ìŠ¤í¬ì˜ persist_dirì—ì„œ ì¼ì–´ë‚œë‹¤.
    """
    vectordb = Chroma(
        collection_name=index_row.collection_name,
        persist_directory=index_row.persist_dir,
        embedding_function=_EMBEDDINGS,
    )
        # ğŸ” ë””ë²„ê¹…: ì»¬ë ‰ì…˜ ë¬¸ì„œ ìˆ˜ë¥¼ í™•ì¸
    try:
        count = vectordb._collection.count()
        if not count:
            # ì—¬ê¸°ì„œ ë°”ë¡œ ì˜ˆì™¸ë¥¼ ë‚´ì£¼ë©´ í”„ë¡ íŠ¸ê°€ ì›ì¸ íŒŒì•… ì‰¬ì›€
            raise HTTPException(409, "Vector index is empty. Re-run indexing for this subject.")
    except Exception:
        # ì¼ë¶€ ë²„ì „ì—ì„œ _collection ì ‘ê·¼ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ â†’ ê²€ìƒ‰ìœ¼ë¡œë„ ì²´í¬
        pass
    return vectordb

# def _load_chroma(vindex: VectorIndexTable) -> Chroma:
#     """RDBì— ì €ì¥ëœ (collection_name, persist_dir)ë¡œ Chroma ì—°ê²°"""
#     return Chroma(
#         collection_name=vindex.collection_name,
#         persist_directory=vindex.persist_dir,
#         embedding_function=_EMBEDDINGS,
#     )

# async def _get_vector_index(session: AsyncSession, user_id: uuid.UUID, subject_id: int) -> VectorIndexTable:
#     """user+subject ì¡°í•©ì˜ ì¸ë±ìŠ¤ 1í–‰ì„ ë¡œë“œ. ì—†ìœ¼ë©´ ì•„ì§ ì—…ë¡œë“œ/ì¸ë±ì‹± ì „ì´ë¯€ë¡œ 404."""
#     q = await session.execute(
#         select(VectorIndexTable).where(
#             VectorIndexTable.user_id == user_id,
#             VectorIndexTable.subject_id == subject_id
#         )
#     )
#     row = q.scalar_one_or_none()
#     if not row:
#         raise HTTPException(404, "No vector index for this subject. Upload materials first.")
#     return row

def _format_source(doc) -> str:
    """í”„ë¡ íŠ¸ì— ë°”ë¡œ ë¿Œë¦´ â€˜ê·¼ê±° í…ìŠ¤íŠ¸â€™ë¡œ ì •ë¦¬ (ë¬¸ì„œëª… + í˜ì´ì§€ or ìŠ¤ë‹ˆí«)"""
    src = doc.metadata.get("source", "Unknown")
    page = doc.metadata.get("page")
    if page is not None:
        return f"{src}, p.{page}"
    snippet = doc.page_content[:70].replace("\n", " ")
    return f"{src}: \"{snippet}...\""

def _label_with_numbers(docs) -> tuple[str, dict[str, str]]:
    """
    ì»¨í…ìŠ¤íŠ¸ ë¬¸ë‹¨ì— [1][2]â€¦ ë¼ë²¨ì„ ë¶€ì—¬í•´ LLMì´ ê·¸ëŒ€ë¡œ ì¸ìš©í•˜ë„ë¡ í•¨.
    ë°˜í™˜: (ë¼ë²¨ì´ ë¶™ì€ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´, { "1": "ë¬¸ì„œëª… p.x", ... })
    """
    parts, idx2src = [], {}
    for i, d in enumerate(docs, start=1):
        parts.append(f"[{i}] {d.page_content}")
        idx2src[str(i)] = _format_source(d)
    return "\n\n".join(parts), idx2src

def _extract_used_citations(answer: str, idx2src: dict[str, str]) -> list[str]:
    """ë‹µë³€ ë‚´ [n]ì„ ì°¾ì•„ ì‹¤ì œ ê·¼ê±° í…ìŠ¤íŠ¸ë¡œ ë§¤í•‘"""
    nums = sorted(set(re.findall(r"\[(\d+)\]", answer)))
    return [f"[{n}] {idx2src[n]}" for n in nums if n in idx2src]

async def ask_and_store(
    db: AsyncSession,
    *, user_id: uuid.UUID, chat_session_id: int, subject_id: int, question: str
) -> QATurnTable:
    """
    1) user+subject ì¸ë±ìŠ¤ ë¡œë“œ â†’ vectordb ê²€ìƒ‰(k=8)
    2) rerankerë¡œ ìƒìœ„ 5ê°œ ì •ë ¬
    3) ì»¨í…ìŠ¤íŠ¸ì— [n] ë¶™ì—¬ question_promptë¡œ LLM í˜¸ì¶œ
    4) ë‹µë³€ + citations JSONì„ qa_turnsì— ì €ì¥ í›„ ë°˜í™˜
    """
    vindex = await _get_vector_index(db, user_id, subject_id)
    vectordb = _load_chroma(vindex)

    retriever = vectordb.as_retriever(search_kwargs={"k": 8})
    #cands = await retriever.abatch([question])  # async-friendly; 1ê°œ ì§ˆì˜
    # docs = cands[0] if cands else []
    # AFTER: í•œ ê±´ ë¹„ë™ê¸° ê²€ìƒ‰
    docs = await retriever.ainvoke(question) 
    
    # ì¬ì •ë ¬
    pairs = [[question, d.page_content] for d in docs]
    scores = _reranker.predict(pairs)
    reranked = [d for d, _ in sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)[:5]]

    labeled_ctx, idx2src = _label_with_numbers(reranked)
    prompt = question_prompt.format(context=labeled_ctx, question=question)
    resp = llm.invoke(prompt)  # LangChain LLM ì¸í„°í˜ì´ìŠ¤

    answer = (getattr(resp, "content", None) or str(resp)).strip()
    used = _extract_used_citations(answer, idx2src)

    turn = QATurnTable(
        chat_session_id=chat_session_id,
        user_id=user_id,
        question=question,
        answer=answer,
        has_answer=(answer.lower() != "no answer"),
        citations=used
    )
    db.add(turn)
    await db.flush()    # qa_turn_id ë¶€ì—¬
    await db.commit()
    await db.refresh(turn)
    return turn
