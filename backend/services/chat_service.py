# ì„¤ëª…: ìŠ¤ë§ˆíŠ¸ Q&A ë„ë©”ì¸ ë¡œì§(ë²¡í„° ê²€ìƒ‰ â†’ ì¬ì •ë ¬ â†’ LLM ë‹µë³€ ìƒì„± â†’ [n] ì¸ë¼ì¸ ì¸ìš© â†’ ERD ì €ì¥ìš© citation í…ìŠ¤íŠ¸ êµ¬ì„±)
from __future__ import annotations
from typing import List, Tuple
import uuid, re

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from fastapi import HTTPException

from langchain_community.vectorstores import Chroma
from sentence_transformers import CrossEncoder

from models.chat_domain import ChatSessionTable, QATurnTable
from models.vector_domain import VectorIndexTable
from services.ai_service_global import _EMBEDDINGS, llm, question_prompt  # ì´ë¯¸ ìˆëŠ” ê³µìš© ëª¨ë“ˆ
import asyncio # ì¶”ê°€
from langchain.schema import Document  # ì¶”ê°€ 


# Colab ì˜ˆì œì™€ ë™ì¼í•œ ì¬ì •ë ¬ ëª¨ë¸(ë¹ ë¥´ê³  ê°€ë²¼ì›€)
_reranker = CrossEncoder("BAAI/bge-reranker-base")

async def _get_vector_index(session: AsyncSession, user_id: uuid.UUID, subject_id: int) -> VectorIndexTable:
    """user+subject ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ 1í–‰ì„ ê°€ì ¸ì˜¨ë‹¤(ì—†ìœ¼ë©´ 404)."""
    q = await session.execute(
        select(VectorIndexTable).where(
            VectorIndexTable.user_id == user_id,
            VectorIndexTable.subject_id == subject_id
        )
    )
    row = q.scalar_one_or_none()
    if not row:
        # ì—…ë¡œë“œ/ì¸ë±ì‹±ì´ ì•„ì§ ì•ˆ ëœ ê³¼ëª©
        raise HTTPException(404, "No vector index for this subject. Upload materials first.")
    return row

def _load_chroma(index_row: VectorIndexTable) -> Chroma:
    """
    RDBì— ì €ì¥ëœ ì»¬ë ‰ì…˜ ì‹ë³„ì(ì´ë¦„/ê²½ë¡œ)ë¡œ Chromaë¥¼ ë¡œë“œí•œë‹¤.
    ì‹¤ì œ ì„ë² ë”©/ê²€ìƒ‰ì€ ë””ìŠ¤í¬ì˜ persist_dirì—ì„œ ì¼ì–´ë‚œë‹¤.
    """
    vectordb = Chroma(
        collection_name=index_row.collection_name,
        persist_directory=index_row.persist_dir,
        embedding_function=_EMBEDDINGS,
    )
        # ğŸ” ë””ë²„ê¹…: ì»¬ë ‰ì…˜ ë¬¸ì„œ ìˆ˜ë¥¼ í™•ì¸
    try:
        count = vectordb._collection.count()
        if not count:
            # ì—¬ê¸°ì„œ ë°”ë¡œ ì˜ˆì™¸ë¥¼ ë‚´ì£¼ë©´ í”„ë¡ íŠ¸ê°€ ì›ì¸ íŒŒì•… ì‰¬ì›€
            raise HTTPException(409, "Vector index is empty. Re-run indexing for this subject.")
    except Exception:
        # ì¼ë¶€ ë²„ì „ì—ì„œ _collection ì ‘ê·¼ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ â†’ ê²€ìƒ‰ìœ¼ë¡œë„ ì²´í¬
        pass
    return vectordb


# ---------- helpers: Colabì˜ label & citation ì¶”ì¶œì„ ì„œë²„ìš©ìœ¼ë¡œ ê·¸ëŒ€ë¡œ ----------
def _format_source(doc: Document) -> str:
    src = doc.metadata.get("source", "Unknown")
    page = doc.metadata.get("page")
    if page is not None:
        return f"{src}, p.{page}"
    snippet = doc.page_content[:70].replace("\n", " ")
    return f"{src}: \"{snippet}...\""

def _label_and_map_documents_multi(docs_lists: List[List[Document]]) -> tuple[str, List[Document], dict]:
    all_docs: List[Document] = []
    labeled_parts: List[str] = []
    idx2src: dict[str, str] = {}

    counter = 1  # âœ… í•­ìƒ 1ë¶€í„° ì‹œì‘ (Colab ë™ì¼)
    for docs in docs_lists:
        for d in docs:
            all_docs.append(d)
            labeled_parts.append(f"[{counter}] {d.page_content}")
            idx2src[str(counter)] = _format_source(d)
            counter += 1

    return "\n\n".join(labeled_parts), all_docs, idx2src

def _filter_used_sources_list(answer_text: str, idx2src: dict[str, str]) -> list[str]:
    nums = sorted(set(re.findall(r"\[(\d+)\]", answer_text)))
    return [f"[{n}] {idx2src[n]}" for n in nums if n in idx2src]


# ---------- í•µì‹¬: Colab QA ìŠ¤í…ë§Œ ìˆ˜í–‰ ----------
async def ask_and_store(
    db: AsyncSession,
    *, user_id: uuid.UUID, chat_session_id: int, subject_id: int, question: str
) -> QATurnTable:
    """
    1) user+subject ì¸ë±ìŠ¤ ë¡œë“œ â†’ vectordb ê²€ìƒ‰(k=8)
    2) rerankerë¡œ ìƒìœ„ 5ê°œ ì •ë ¬
    3) ì»¨í…ìŠ¤íŠ¸ì— [n] ë¶™ì—¬ question_promptë¡œ LLM í˜¸ì¶œ
    4) ë‹µë³€ + citations JSONì„ qa_turnsì— ì €ì¥ í›„ ë°˜í™˜
    """
    # 0) ì¸ë±ìŠ¤/Chroma ë¡œë“œ
    vindex = await _get_vector_index(db, user_id, subject_id)
    vectordb = _load_chroma(vindex)

    # 1) retrieval (Colab: retriever.get_relevant_documents)
    retriever = vectordb.as_retriever(search_kwargs={"k": 8})
    # retriever.get_relevant_documents ëŠ” sync â†’ ìŠ¤ë ˆë“œë¡œ ëŒë ¤ ë¹„ë™ê¸°í™”
    loop = asyncio.get_running_loop()
    docs: List[Document] = await loop.run_in_executor(
        None, retriever.get_relevant_documents, question
    )
    
    # 2) rerank (Colab : CrossEncoder.predict)
    pairs = [[question, d.page_content] for d in docs]
    scores = await loop.run_in_executor(None, _reranker.predict, pairs)
    reranked = [d for d, _ in sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)[:5]]

    # 3) ì»¨í…ìŠ¤íŠ¸ì— [n] ë¼ë²¨ ë¶€ì—¬ (Colabê³¼ ë™ì¼)
    labeled_ctx, _all_docs, idx2src = _label_and_map_documents_multi([reranked])
    
    # 4) LLM í˜¸ì¶œ (Colab ë™ì¼ í”„ë¡¬í¬íŠ¸)
    prompt = question_prompt.format(context=labeled_ctx, question=question)
    resp = llm.invoke(prompt)  # langchain-google-genai ChatGoogleGenerativeAI
    answer = (getattr(resp, "content", None) or str(resp)).strip()

    answer = (getattr(resp, "content", None) or str(resp)).strip()
    
    # 5) ë‹µë³€ ì† [n] â†’ ì¸ìš© í…ìŠ¤íŠ¸ ë§¤í•‘ (Colab ë™ì¼)
    used_citations = _filter_used_sources_list(answer, idx2src)  # ["[1] ì†ŒìŠ¤...", "[2] ..."]

    if not used_citations and idx2src:
        used = [f"[1] {idx2src['1']}"]
        answer = answer + " [1]"

    # 6) ì €ì¥
    turn = QATurnTable(
        chat_session_id=chat_session_id,
        user_id=user_id,
        question=question,
        answer=answer,
        has_answer=(answer.lower() != "no answer"),
        citations=used_citations,
    )
    db.add(turn)
    await db.flush()    # qa_turn_id ë¶€ì—¬
    await db.commit()
    await db.refresh(turn)
    return turn
